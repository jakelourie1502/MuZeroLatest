Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [ 1.3303642   1.73391813 -1.96557132 -1.16019989  1.32058116  1.5211962
 -0.10428687  1.18781482 -1.19272329 -0.46526768 -0.00787157  0.40505829
  0.50681875  0.5679318   0.80912874  0.05918509  0.25836774  0.23675694
 -0.93759154  0.97636031 -0.78126206  1.47371759  0.47516984 -2.0116053
 -0.37498268  0.16540014  1.09666593 -0.25767258 -0.61345167 -1.26289237
 -0.29743092  0.5095965  -2.19721814  1.19706616  0.87536021]
then printing the same exp r:  [-0.15925009548664093, -0.15920370817184448, -0.15920239686965942, -0.15923117101192474, -0.15920239686965942, -0.1592496633529663, -0.15920239686965942, -0.15923117101192474, -0.15926943719387054, -0.15920370817184448, -0.15925009548664093, -0.15920370817184448, -0.15927031636238098, -0.15927031636238098, -0.15923044085502625, -0.15927031636238098, -0.15923044085502625, -0.15927031636238098, -0.15925031900405884, -0.1592704951763153, -0.15923044085502625, -0.15927031636238098, -0.15927031636238098, -0.15920370817184448, -0.15925009548664093, -0.15925009548664093, -0.15920370817184448, -0.15926943719387054, -0.15926943719387054, -0.15923017263412476, -0.15927031636238098, -0.1592489778995514, -0.15923051536083221, -0.15924955904483795, -0.15926916897296906]
0 : 0.0
[[237. 102.  31.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [118.  59.  20.   1.   0.   0.   1.   0.   0.   0.   0.   0.]
 [ 81.  50.  16.   2.   1.   1.   2.   1.   0.   0.   0.   0.]
 [ 64.  35.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]
Test reward:  0.0
LR:  0.0
replay buffer size:  833
training steps:  0
Average siam loss:  0.012136006164837454
Average value from last batch of unclaimed novelty:  tensor(0.0865, dtype=torch.float64)
Average value from last batch of predicted nov:  -0.0706702311668775
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [ 1.57255017 -0.85645177  0.57741341  0.55739327]
then printing the same exp r:  [-0.3338230848312378, -0.3394465744495392, -0.3411087393760681, -0.031827885657548904]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [0.73157074 0.75447789 0.62815839 0.54501166 0.39611922 0.31812431]
then printing the same exp r:  [0.21015037596225739, 0.21015037596225739, 0.15294210612773895, 0.20944929122924805, 0.12200815230607986, 0.35347145795822144]
Checking the total Q and that Qe samples 0.029443965047490785 -0.32284149362741554
Checking that immediate novelty and rootnode V can be smaller than 0:  -0.0096 -0.17720088362693787
10 : 0.0
[[3150. 1259.  290.    0.    0.    0.    0.    0.    0.    0.    0.    0.]
 [1462.  659.  189.   12.    5.    0.    1.    0.    0.    0.    0.    0.]
 [1064.  543.  150.   45.   13.    2.    2.    1.    0.    0.    0.    0.]
 [1025.  519.  171.   10.    5.    0.    0.    0.    0.    0.    0.    0.]]
Printing a sample from n step novelty returns, should be around 0 on average, going up to 9 max:  [-0.0000803   0.04380834  0.04380834  0.04380834  0.04380834  0.04380834
  0.04380834  0.04380834  0.04380834  0.04380834  0.04380834  0.04380834
  0.04380834  0.04380834  0.04380834  0.04380834  0.04380834  0.04380834
  0.04380834  0.04380834  0.04380834  0.21035571  0.34520964  0.31022107
  0.27134489  0.22814913  0.2361044 ]
then printing the same exp r:  [0.024580035358667374, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.07334519177675247, 0.01739463023841381, 0.26233822107315063]
Checking the total Q and that Qe samples 0.46073296978060435 0.44596026300069813
Test reward:  0.0
LR:  0.0012
replay buffer size:  10577
training steps:  10
Average siam loss:  -0.7648501945659518
Average value from last batch of unclaimed novelty:  tensor(-0.1340, dtype=torch.float64)
Average value from last batch of predicted nov:  -0.06468613551057471
